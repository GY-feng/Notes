# 4-使用张量表征真实数据

神经网络当中的所以参数都是张量，比如：权重、偏置、输入输出

## 4.1处理图像

图像：被表示为一个排列在具有高度和宽度的规则网络的标量集合，其中高度和宽度以像素为单位
（标量集合： 图像中的每个像素都是一个标量，它表示图像在特定位置上的亮度或颜色值。这些标量值可以是灰度值（单通道图像）或颜色通道的组合（彩色图像）。）
表示像素值的标量通常使用8位整数编码，但也会在工业当中使用更高的12/16位

颜色通道：颜色编码为数字：RGB，可以把一个颜色通道看做一个灰度强度图，只对应所讨论的颜色

加载图像文件：

```py
import imageio

img_arr=imageio.imread('文件地址')
img_arr.shape()
#使用torchvision也是很好的！
```
img是一个三个维度类似Numpy数组的对象，两个空间维度：宽度和高度。第三个维度对应红绿蓝通道。
输出Numpy数组的库可以获得一个pytorch张量，注意：pytorch对应的张量要求：C×H×W（通道，高度，宽度）

改变布局：
```py
img=torch.from_numpy(img_arr)
out=img.permute(2,0,1)#第一个维度（2）现在将成为新张量的第一个维度，第二个维度（0）成为第二个维度，第三个维度（1）成为第三个维度。换句话说，这行代码将原始张量的通道维度移动到了第一个位置，高度和宽度维度分别移到了第二和第三个位置。
```
给定一个HxWxC的通道
permute使得每个旧的维度得到一个合适的布局

创建一个多图的数据集作为神经网络的输入：以获得一个N×C×H×W的张量
更好的方法：预先分配一个适当大小的张量，并且使用目录的图像来加载它：
```py
batch_size=3
#批处理将由3幅高度256像素，宽度256像素的RGB图像组成
batch=torch.zeros(batch_size,3,256,256)

【代码略】
```

正规化数据：

将浮点数的数值进行归一化以方便后续的处理方法：
方案A：将所有像素除以255
方案B:计算输入数据的均值和标准差，并且对其进行缩放，使得每个通道的均值为0，标准差为1

三维图像：可以采用volread()函数加载一个CT样本（五维）

## 4.3表示表格数据

常见的表数据：电子表格、CSV、数据库
每一行包含一个样本/记录，一列包含关于样本的一部分信息

python如何加载数据：
1，自带的CSV
2，使用Numpy
3，使用pandas（最好用，但在本例当中不用）

```py
path="这里填写路径"
wine_np=np.loadtxt(path,dtype=np.float32,delimiter=";",skiprows=1)

col_list=next(csv.reader(open(path)),delimiter=';')

wineq=torch.from_numpy(wine_np)#numpy转为张量
```

值：
连续值：严格有序，比如1km,5km...
序数值：有排序意义，映射关系：比如大杯为1，中杯为2，小杯为3
分类值：没有排序意义和数字意义

独热编码：
将得分编码到10个元素组成的向量当中，比如：得分1：(1,0,0,0,0,0,0,0,0,0),得分5(0,0,0,0,1,0,0,0,0,0)

scatter_方法的语法如下：

python
torch.Tensor.scatter_(dim, index, src)
其中：

dim：指定在哪个维度上进行散布操作。
index：一个张量，用于指定源张量 src 中元素要被散布到的目标位置。index 张量的形状必须和源张量的形状在 dim 维度上是一致的，或者是可以广播成一致的形状。
src：一个张量，用于提供要散布到目标位置的值。
scatter_方法的作用是将 src 张量中的值按照 index 张量中指定的索引，散布到调用者张量中指定的维度上。例如，如果在一个一维张量上调用 scatter_ 方法，在给定的索引位置将会用 src 中对应位置的值来替换调用者张量中的值。

下面是一个示例，演示了如何使用 scatter_ 方法：
``` py

import torch

# 创建一个目标张量
target = torch.zeros(3, 4)

# 创建一个索引张量
index = torch.tensor([[0, 1, 2],
                      [1, 2, 0]])

# 创建一个源张量
src = torch.tensor([[1, 2, 3],
                    [4, 5, 6]])

# 在维度0上进行散布操作
target.scatter_(0, index, src)

print(target)
运行结果将会是：

tensor([[1, 0, 0, 0],
        [0, 4, 5, 0],
        [0, 0, 0, 6]])
在这个例子中，源张量 src 中的值根据索引张量 index 在维度0上进行了散布操作，并替换了目标张量 target 中对应位置的值。



path="这里填写路径"
wine_np=np.loadtxt(path,dtype=np.float32,delimiter=";",skiprows=1)

col_list=next(csv.reader(open(path)),delimiter=';')

wineq=torch.from_numpy(wine_np)#numpy转为张量

target=wineq[:,-1].long()

#如果得分是完全离散的，/得分介于整数得分之间的定量分数（比如：2.4）那么独热编码合适
#创建了一个全零张量 target_onehot，形状为 (target.shape[0], 10)，其中 target.shape[0] 表示张量的行数，
# 通常用于表示样本数量，而 10 表示每个样本的长度，这里是指要编码的类别数量。
target_onehot=torch.zeros(target.shape[0],10)
#参数：
#1：这是填充的维度，即在目标张量中的哪个维度进行填充。在这里，1 表示按行填充，也就是在每一行的指定位置进行填充。
#target.unsqueeze(1)：这是要填充的索引，target 是原始的标签张量，unsqueeze(1) 的作用是在索引维度上增加一个维度，
# 使其变成列向量，以便与 target_onehot 的行对应。这样，每个样本的标签值就成为了一个列向量。
#1.0：这是要填充的值，即将源张量的值填充到目标张量的指定位置。在这里，使用 1.0 表示将源张量的值填充到目标张量相应位置并设为 1.0，实现了独热编码的效果。
target_onehot.scatter_(1,target.unsqueeze(1),1.0)
#使用scatter_方法获得一个独热编码，方法沿着参数提供的索引方向将源张量的值填充到输入张量当中
```
scatter_的参数：1，指定以下两个参数的维度。2，一个列张量，表示要散射元素的索引张量。3，包含要散射元素的张量/要散射的单个标量（0.1）


import csv
import numpy as np
import torch


path="这里填写路径"
wine_np=np.loadtxt(path,dtype=np.float32,delimiter=";",skiprows=1)

col_list=next(csv.reader(open(path)),delimiter=';')

wineq=torch.from_numpy(wine_np)#numpy转为张量

target=wineq[:,-1].long()

#如果得分是完全离散的，/得分介于整数得分之间的定量分数（比如：2.4）那么独热编码合适
#创建了一个全零张量 target_onehot，形状为 (target.shape[0], 10)，其中 target.shape[0] 表示张量的行数，
# 通常用于表示样本数量，而 10 表示每个样本的长度，这里是指要编码的类别数量。
target_onehot=torch.zeros(target.shape[0],10)
#参数：
#1：这是填充的维度，即在目标张量中的哪个维度进行填充。在这里，1 表示按行填充，也就是在每一行的指定位置进行填充。
#target.unsqueeze(1)：这是要填充的索引，target 是原始的标签张量，unsqueeze(1) 的作用是在索引维度上增加一个维度，
# 使其变成列向量，以便与 target_onehot 的行对应。这样，每个样本的标签值就成为了一个列向量。
#1.0：这是要填充的值，即将源张量的值填充到目标张量的指定位置。在这里，使用 1.0 表示将源张量的值填充到目标张量相应位置并设为 1.0，实现了独热编码的效果。
target_onehot.scatter_(1,target.unsqueeze(1),1.0)
#使用scatter_方法获得一个独热编码，方法沿着参数提供的索引方向将源张量的值填充到输入张量当中


data=wineq[:,:,-1] # 选择所有行和除了最后一列以外的所有列
#dim=0表示沿维度0进行规约
#获得平均值
data_mean=torch.mean(data,dim=0)
# 获得标准差
data_var=torch.var(data,dim=0)
# 通过减去平均值并且除以标准差来对数据进行归一化
data_normalized=(data-data_mean)/torch.sqrt(data_var)